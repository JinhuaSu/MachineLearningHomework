{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression hw in week 13\n",
    "\n",
    "**info**\n",
    "\n",
    "SuJinhua 2017201620\n",
    "\n",
    "**DIY regression function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x,y):\n",
    "    x = np.hstack((np.ones((x.shape[0],1)),x))\n",
    "    beta = np.linalg.inv(x.T.dot(x)).dot(x.T.dot(y))\n",
    "    return beta\n",
    "def logit_regression(x,y,t=100,init_beta =False,beta = None,method = 'newton',lr = 0.001):\n",
    "    x = np.hstack((np.ones((x.shape[0],1)),x))\n",
    "    if init_beta == False:\n",
    "        beta = np.zeros((x.shape[1],1))\n",
    "    def p1(x,y,beta):\n",
    "        return 1/(1+np.exp(-1 * x.dot(beta)))\n",
    "    def derivate_1(x,y,beta):\n",
    "        return -1 * x.T.dot((y-p1(x,y,beta).T).T)\n",
    "    def derivate_2(x,y,beta):\n",
    "        tmp = p1(x,y,beta)\n",
    "        tmp = tmp*(1-tmp)\n",
    "        return x.T.dot(x*tmp)\n",
    "    if method == 'newton':\n",
    "        for i in range(t):\n",
    "            beta = beta - np.linalg.inv(derivate_2(x,y,beta)).dot(derivate_1(x,y,beta))\n",
    "    elif method == 'simple':\n",
    "        for i in range(t):\n",
    "            beta = beta - lr * derivate_1(x,y,beta)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5\n",
    "\n",
    "- For group data, we use linear regression to estimate the logistic regression.\n",
    "- By some data operations, we can get the raw ungrouped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>ni</th>\n",
       "      <th>y=1</th>\n",
       "      <th>y=0</th>\n",
       "      <th>pi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.29167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>389</td>\n",
       "      <td>146</td>\n",
       "      <td>243</td>\n",
       "      <td>0.37564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>26</td>\n",
       "      <td>57</td>\n",
       "      <td>0.31548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num  x1  x2   ni  y=1  y=0       pi\n",
       "0    1  22   0    3    0    3  0.12500\n",
       "1    2  22   1   11    3    8  0.29167\n",
       "2    3  22   2  389  146  243  0.37564\n",
       "3    4  22   3   83   26   57  0.31548\n",
       "4    5  37   0    4    3    1  0.70000"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "df1 = pd.read_excel('table10-11.xlsx')\n",
    "df2 = pd.read_excel('table10-12.xlsx')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['p_'] = np.log(df1['pi']/(1 - df1['pi']))\n",
    "y = df1['p_'].to_numpy()\n",
    "x = df1[['x1','x2']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont: -0.1444940115598669\n",
      "ceof: [-0.00631765 -0.13643885]\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(x,y)\n",
    "print('cont:',lr.intercept_)\n",
    "print('ceof:',lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14449401, -0.00631765, -0.13643885])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subproblem 1\n",
    "\n",
    "Since the grouped data has an estimate of probability, the logistic regression can be converted to linear regression. The coefficients are all negative, that means that with age and education increase, citizen may be less afraid of the stranger. But the influence of age increase is implicit, eduction may be a good factor to explain the explantory variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: [0.11996409]\n",
      "ceof: [[ 0.00099379 -0.30977755]]\n"
     ]
    }
   ],
   "source": [
    "x2,y2 = df_new[['x1_d','x2_d']].to_numpy(),df_new['y'].to_numpy()\n",
    "logi_r = linear_model.LogisticRegression(solver='newton-cg')\n",
    "logi_r.fit(x2,y2)\n",
    "print('intercept:',logi_r.intercept_)\n",
    "print('ceof:',logi_r.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_d</th>\n",
       "      <th>x2_d</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1_d  x2_d  y\n",
       "0    22     0  0\n",
       "1    22     0  0\n",
       "2    22     0  0\n",
       "3    22     1  1\n",
       "4    22     1  1"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_seperate_data(df):\n",
    "    x1_list,x2_list,y_list = [],[],[]\n",
    "    for i in range(len(df)):\n",
    "        n = df.loc[i,'ni']\n",
    "        n_1 = df.loc[i,'y=1']\n",
    "        x1_list += [df.loc[i,'x1']] * n\n",
    "        x2_list += [df.loc[i,'x2']] * n\n",
    "        y_list += [1] * n_1 + [0] * (n - n_1)\n",
    "    return pd.DataFrame({'x1_d':x1_list,'x2_d':x2_list,'y':y_list})\n",
    "df_new = generate_seperate_data(df1)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12862471],\n",
       "       [ 0.00097967],\n",
       "       [-0.31368478]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_regression(df_new[['x1_d','x2_d']].to_numpy(),df_new['y'].to_numpy(),method = 'newton',lr =0.1,t = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subproblem 2\n",
    "\n",
    "As for the ungrouped data, we use newton method to iterate the beta. To check my DIY logistic regression correctness, I use sklearn regression package to check the result. This time the coefficient of the age(x1) is positive but really small, while the coefficient of education(x2) becomes more influent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>h</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num     h  y\n",
       "0    1  1.50  0\n",
       "1    2  1.52  0\n",
       "2    3  1.54  0\n",
       "3    4  1.56  0\n",
       "4    5  1.58  1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: [-1.88627383]\n",
      "ceof: [[0.80832952]]\n"
     ]
    }
   ],
   "source": [
    "x3 = df2[['h']].to_numpy()\n",
    "y3 = df2['y'].to_numpy()\n",
    "logi_r2 = linear_model.LogisticRegression(solver='lbfgs')\n",
    "logi_r2.fit(x3,y3)\n",
    "print('intercept:',logi_r2.intercept_)\n",
    "print('ceof:',logi_r2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logi_r2.predict(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-14.59176501],\n",
       "       [  7.98143472]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = logit_regression(x3,y3)\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1], dtype=int16)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def p1(x,y,beta):\n",
    "    return 1/(1+np.exp(-1 * x.dot(beta)))\n",
    "my_pred = p1(np.hstack((np.ones((len(x3),1)),x3)),y3,beta).squeeze()>0.5\n",
    "my_pred = my_pred.astype(np.int16) \n",
    "my_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion\n",
    "\n",
    "I use my DIY logistic regression to predict train data and find one feature could not fully explain the result. There are ignored variables, such as the soomth of the ground and the shape of the glass. I use the sklearn package to fit the logistic regression, but it gives a different result. However the beta0 / beta1 = 1.8, which means the 1.8 meter is the therohold of the glass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
